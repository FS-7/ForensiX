{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7dac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "loc = \"./data/\"\n",
    "\n",
    "call_logs = sqlite3.connect(loc + \"call_log.db\")\n",
    "call_logs_cursor = call_logs.cursor()\n",
    "\n",
    "call_log_documents = pd.DataFrame(columns=[[\"Number\", \"Owner\", \"Time\", \"Duration\", \"Type\", \"CountryISO\",]])\n",
    "for i, c in enumerate(call_logs_cursor.execute(\"SELECT * FROM CALLS\").fetchall()):\n",
    "    call_log_documents.loc[i] = [ c[1], c[12], datetime.fromtimestamp(int(c[5])//1000).strftime(\"%d-%m-%Y %H:%M:%S\"), c[6], \"INCOMING\" if c[8]==1 else \"OUTGOING\" if c[8] == 2 else \"MISSED\" if c[8] == 3 else \"REJECTED\", c[19] ]\n",
    "    \n",
    "call_log_documents\n",
    "\n",
    "sms = sqlite3.connect(loc + \"sms.db\")\n",
    "sms_cursor = sms.cursor()\n",
    "\n",
    "sms_documents = pd.DataFrame(columns = [\"Address\", \"Body\", \"Date Sent\", \"Date Received\", \"Type\", \"Seen\"])\n",
    "for i, c in enumerate(sms_cursor.execute(\"SELECT * FROM SMS\").fetchall()):\n",
    "    sms_documents.loc[i] = [ c[2], c[12], datetime.fromtimestamp(int(c[5])/1000).strftime(\"%d-%m-%Y, %H:%M:%S\") if c[9] == 1 else datetime.fromtimestamp(int(c[4])/1000).strftime(\"%d-%m-%Y, %H:%M:%S\"), datetime.fromtimestamp(int(c[4])/1000).strftime(\"%d-%m-%Y, %H:%M:%S\"), \"Received\" if c[9] == 1 else \"Sent\", \"True\" if c[18] == 1 else \"False\" ]\n",
    "\n",
    "sms_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be278a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b416bec5e8a04cad8f9084a72af04c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/gemma-2-2b-it Loaded!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch, sqlite3\n",
    "import asyncio\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 12\n",
    "language = \"en\"\n",
    "gemma = \"google/gemma-2-2b-it\"\n",
    "nlp = gemma\n",
    "nlp_model = None\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "def load_NLP():\n",
    "    global nlp_model\n",
    "    nlp_model = pipeline(\"text-generation\", model=nlp, model_kwargs={\"torch_dtype\": torch_dtype}, device=device)\n",
    "    if nlp_model != None:\n",
    "        print(f\"{nlp} Loaded!\")\n",
    "\n",
    "load_NLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d3cb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get all messages\n",
      "SQL: ```sql\n",
      "SELECT * FROM sms;\n",
      "```\n",
      "Results:  [(1, 1, '+16505551212', 2, 1763649906518, 1763649911000, 0, 1, -1, 1, 0, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhCZ3eMPw/NJNq4kblZMS0n5', 'Morning Bob! You awake?', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (2, 1, '+16505551212', None, 1763649943149, 0, None, 1, -1, 2, None, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhDjjU8W09NCgKk5bzpsDr6K', 'Barely. Need coffee first.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (3, 1, '+16505551212', 2, 1763649952769, 1763649958000, 0, 1, -1, 1, 0, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhC39iDFbgNOfK+qd3qgZC1F', 'Same. Rough night?', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (4, 1, '+16505551212', None, 1763649974076, 0, None, 1, -1, 2, None, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhC64ELCLLRCTadlK7lUWGf8', 'I stayed up fixing that server issue.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (5, 1, '+16505551212', 2, 1763649981539, 1763649987000, 0, 1, -1, 1, 0, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhDMfj7HkkVKrpURnAH9Sx4O', 'Oh wow. Did it finally work?', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (6, 1, '+16505551212', None, 1763649989470, 0, None, 1, -1, 2, None, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhC0RGm5399EXYXoy8JnDzN8', 'Yeah. Took forever though.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (7, 1, '+16505551212', 2, 1763649994900, 1763650000000, 0, 1, -1, 1, 0, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhDEb+3x56NNZJTE2ItsK8B+', \"You're a hero lol.\", None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (8, 1, '+16505551212', None, 1763650000910, 0, None, 1, -1, 2, None, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhC/77iPuJhO0YYD4/av48jw', 'I accept praise in the form of pastries.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (9, 1, '+16505551212', 2, 1763650020065, 1763650025000, 0, 1, -1, 1, 0, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhA/PstETHxGLqXlZMLBpBqL', \"I'll see if there's donuts in the break room.\", None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (12, 2, '+17899977860', None, 1763658238899, 0, None, 1, -1, 2, None, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhDDbmduKPpPlpV1MghWwrk0', 'You’ve pushed me for the last time. Keep it up and you’re going to find out exactly why nobody crosses me twice.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (13, 2, '+17899977860', 1, 1763658257034, 1763658257000, 0, 1, -1, 1, 0, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhDeqyKk6Y5Iuq6vrM00wVkH', 'Good. I’d hate for you to run when things get messy. Let’s see if you can handle what you started.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (14, 2, '+17899977860', None, 1763658266186, 0, None, 1, -1, 2, None, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhAo30ugwqJL0KbgnYsU6ytQ', 'Say whatever you want. You’re about to learn that I don’t back down.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (15, 3, '+19999999999', None, 1763666952804, 1763666953000, 0, 1, -1, 1, 0, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhAwUm8jM1FGMa2PIaqqvOTr', 'Your so-called Dawn Legion is a stain on this realm. Our Order will reshape the world in shadow, whether your light survives or not.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (16, 3, '+19999999999', None, 1763666964343, 0, None, 1, -1, 2, None, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhDvPjlUNtVHtYQFSP0lVGxu', 'Your shadows are nothing but fear masquerading as strength. The Legion will burn away every twisted doctrine your Order spreads.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (17, 3, '+19999999999', None, 1763666974669, 1763666975000, 0, 1, -1, 1, 0, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhA6zEA6Uv5Mxa1fELT+7YtN', 'You cling to that naive radiance like it protects you. The Obsidian Order’s rise is inevitable. Oppose us, and you’ll be swept aside with the rest of the deluded.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (18, 3, '+19999999999', None, 1763666983474, 0, None, 1, -1, 2, None, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhCuuNWr/A1LDJijQ+8b9k+5', 'We don’t bow to tyrants hiding behind darkness. If it’s a clash of convictions you want, the Legion stands ready. We won’t let your corruption swallow the realm.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1), (19, 2, '+17899977860', 1, 1763667077614, 1763667077000, 0, 1, -1, 1, 0, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhBL4rL91tVD84DSExAAqMZl', 'Oh I’m shaking. You talk big but all I see is someone desperate to look tough.', None, 0, 1, -1, 'com.google.android.apps.messaging', 1)]\n",
      "Output:  This data appears to be a collection of messages, likely from a messaging app. Here's a breakdown of the information:\n",
      "\n",
      "**Data Structure:**\n",
      "\n",
      "* Each entry is a dictionary representing a single message conversation. \n",
      "* Each message has:\n",
      "    * **`[1, 1, '+16505551212', 2, 1763649906518, 1763649911000, 0, 1, -1, 1, 0, 'proto:CjoKImNvbS5nb29nbGUuYW5kcm9pZC5hcHBzLm1lc3NhZ2luZy4SFCIAKhCZ3eMPw/NJNq4kblZMS0n5', 'Morning Bob! You awake?', None, 0, 1, -1, 'com.google.android.apps.messaging', 1]`** \n",
      "    * **`[1, 1, '+16505551212', 2, 1763649906518\n"
     ]
    }
   ],
   "source": [
    "def generate_query(query):\n",
    "    try:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\", \"content\": \n",
    "                f\"\"\"\n",
    "                Context: You are a SQL generator. \n",
    "                Given the following database schema:\n",
    "                    Table: sms alias Messages\n",
    "                    Columns:\n",
    "                    - id (integer)\n",
    "                    - Address (text)\n",
    "                    - Date Sent (date)\n",
    "                    - Date Received (date)\n",
    "                    - Type (text)\n",
    "                    - Body (text)\n",
    "                    - Seen (boolean)\n",
    "                    \n",
    "                    Table: Contacts\n",
    "                    Columns:\n",
    "                    - id (integer)\n",
    "                    - name (text)\n",
    "                    - number (number)\n",
    "                    - email (text)\n",
    "                    \n",
    "                    Table: Call Logs\n",
    "                    Columns:\n",
    "                    - id (integer)\n",
    "                    - Owner (text)\n",
    "                    - Date Time (number)\n",
    "                    - Duration (number)\n",
    "                    - Type (text)\n",
    "                    \n",
    "                    Table: Files\n",
    "                    Columns:\n",
    "                    - path (text)\n",
    "                    - name (text)\n",
    "                    - parent (text)\n",
    "                    - size (number)\n",
    "                    - datetime (datetime)\n",
    "                    - ext (text) alias type\n",
    "                Convert the following user question into a correct, safe SQL query. \n",
    "                Return only SQL, no explanations.\n",
    "                Query: {query}\n",
    "                \"\"\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        outputs = nlp_model(messages, max_new_tokens=128)\n",
    "        assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "        return assistant_response\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return \n",
    "\n",
    "def run_query(query):\n",
    "    query = query[6:-3]\n",
    "\n",
    "    if str(query).lower().startswith(\"select\"):\n",
    "        return\n",
    "    conn = sqlite3.connect(\"./data/sms.db\")\n",
    "    cur = conn.cursor()\n",
    "    output = cur.execute(\n",
    "        query,\n",
    "        []\n",
    "    ).fetchall()\n",
    "    return output\n",
    "    \n",
    "def convert_to_nlp(results):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": \n",
    "            f\"\"\"\n",
    "            Data: {results}\n",
    "            Convert the following data in human readable format\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    try:\n",
    "        outputs = nlp_model(messages, max_new_tokens=256)\n",
    "        assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "        return assistant_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def hello():\n",
    "    query = \"get all messages\"\n",
    "    print(query)\n",
    "\n",
    "    sql_query = generate_query(query)\n",
    "    print(\"SQL:\", sql_query)\n",
    "\n",
    "    results = run_query(sql_query)\n",
    "    print(\"Results: \", results)\n",
    "\n",
    "    output = convert_to_nlp(results)\n",
    "    print(\"Output: \", output)\n",
    "\n",
    "hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba7f5855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\REPOSITORIES\\WEB\\Forensix\\.venv\\Lib\\site-packages\\ctranslate2\\__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "e:\\REPOSITORIES\\WEB\\Forensix\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "e:\\REPOSITORIES\\WEB\\Forensix\\.venv\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-24 23:19:21 - whisperx.asr - INFO - No language specified, language will be detected for each audio file (increases inference time)\n",
      "2025-11-24 23:19:21 - whisperx.vads.pyannote - INFO - Performing voice activity detection using Pyannote...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Python\\Python313\\Lib\\inspect.py:1020: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.6. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint e:\\REPOSITORIES\\WEB\\Forensix\\.venv\\Lib\\site-packages\\whisperx\\assets\\pytorch_model.bin`\n",
      "e:\\REPOSITORIES\\WEB\\Forensix\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.8.0+cpu. Bad things might happen unless you revert torch to 1.x.\n",
      "large-v3 Loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9250b02097514360b815528667355fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/gemma-2-2b-it Loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoritzLaurer/deberta-v3-large-zeroshot-v2.0 Loaded!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import whisperx\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "class ASR:\n",
    "    def __init__(self, device, compute_type):\n",
    "        self.model = None\n",
    "        self.__asr = \"large-v3\"\n",
    "        self.load_model(device, compute_type)\n",
    "    \n",
    "    def load_model(self, device, compute_type):\n",
    "        self.model = whisperx.load_model(self.__asr, device, compute_type=str(torch_dtype).split(\".\")[1])\n",
    "        if self.model != None:\n",
    "            print(f\"{self.__asr} Loaded!\")\n",
    "            \n",
    "    def isLoaded(self):\n",
    "        return False if self.model == None else True\n",
    "    \n",
    "class NLP:\n",
    "    def __init__(self, device, compute_type):\n",
    "        self.__nlp = \"google/gemma-2-2b-it\"\n",
    "        self.model = None\n",
    "        self.load_model(device, compute_type)\n",
    "    \n",
    "    def load_model(self, device, compute_type):\n",
    "        self.model = pipeline(\"text-generation\", model=self.__nlp, model_kwargs={\"torch_dtype\": torch_dtype}, device=device)\n",
    "        if self.model != None:\n",
    "            print(f\"{self.__nlp} Loaded!\")\n",
    "        \n",
    "    def isLoaded(self):\n",
    "        return False if self.model == None else True\n",
    "        \n",
    "class ZSC:\n",
    "    def __init__(self, device, compute_type):\n",
    "        self.__zsc = \"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\"\n",
    "        self.model = None\n",
    "        self.load_model(device, compute_type)\n",
    "    \n",
    "    def load_model(self, device, compute_type):\n",
    "        self.model = pipeline(\"zero-shot-classification\", model=self.__zsc)\n",
    "        if self.model != None:\n",
    "            print(f\"{self.__zsc} Loaded!\")\n",
    "        \n",
    "    def isLoaded(self):\n",
    "        return False if self.model == None else True\n",
    "        \n",
    "#asr = ASR().load_model(device, torch_dtype)\n",
    "#NLP.load_model()\n",
    "asr = ASR(device, torch_dtype)\n",
    "nlp = NLP(device, torch_dtype)\n",
    "zsc = ZSC(device, torch_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706d4d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "sqlite = sqlite3.connect(\"./test.db\")\n",
    "cur = sqlite.cursor()\n",
    "cur.execute(\"DROP TABLE IF EXISTS MESSAGES;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS CALL_LOGS;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS CONTACTS;\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS FILES;\")\n",
    "cur.execute(\n",
    "    '''\n",
    "    CREATE TABLE IF NOT EXISTS MESSAGES(\n",
    "        ADDRESS VARCHAR(100) NOT NULL,\n",
    "        BODY VARCHAR(512) NOT NULL,\n",
    "        DATE_SENT DATETIME NOT NULL,\n",
    "        DATE_RECEIVED DATETIME NOT NULL,\n",
    "        TYPE VARCHAR(10) NOT NULL,\n",
    "        SEEN VARCHAR(4) NOT NULL\n",
    "    );\n",
    "    '''\n",
    ")\n",
    "cur.execute(\n",
    "    '''\n",
    "    CREATE TABLE IF NOT EXISTS CALL_LOGS(\n",
    "        NUMBER VARCHAR(10) NOT NULL,\n",
    "        DATE DATETIME NOT NULL,\n",
    "        DURATION INT NOT NULL,\n",
    "        TYPE VARCHAR(10) NOT NULL\n",
    "    );\n",
    "    '''\n",
    ") \n",
    "cur.execute(\n",
    "    '''\n",
    "    CREATE TABLE IF NOT EXISTS CONTACTS(\n",
    "        NAME VARCHAR(50) NOT NULL,\n",
    "        NUMBER VARCHAR(10) NOT NULL,\n",
    "        GROUP_ID INT NOT NULL,\n",
    "        EMAIL VARCHAR(255) NOT NULL\n",
    "    );\n",
    "    '''\n",
    ")\n",
    "cur.execute(\n",
    "    '''\n",
    "    CREATE TABLE IF NOT EXISTS FILES(\n",
    "        PATH VARCHAR(260) NOT NULL PRIMARY KEY,\n",
    "        NAME VARCHAR(255) NOT NULL,\n",
    "        DIRECTORY VARCHAR(255) NOT NULL,\n",
    "        SIZE INT NOT NULL,\n",
    "        DATETIME DATETIME NOT NULL,\n",
    "        EXT VARCHAR(5) NOT NULL\n",
    "    );\n",
    "    '''    \n",
    ") \n",
    "sms = [\n",
    "    [\"7899977860\",\"Oh I’m shaking. You talk big but all I see is\",\"21-11-2025 01:01:17\",\"21-11-2025 01:01:17\",\"Received\",\"True\"],\n",
    "    [\"9999999999\",\"We don’t bow to tyrants hiding behind darkness\",\"21-11-2025 00:59:43\",\"21-11-2025 00:59:43\",\"Sent\",\"True\"]\n",
    "]\n",
    "cur.executemany(\n",
    "    '''\n",
    "    INSERT INTO MESSAGES(ADDRESS, BODY, DATE_SENT, DATE_RECEIVED, TYPE, SEEN) VALUES(?, ?, ?, ?, ?, ?);\n",
    "    '''\n",
    "    , sms\n",
    ")\n",
    "sqlite.commit()\n",
    "cur.close()\n",
    "sqlite.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4391a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "sqlite = sqlite3.connect(\"../../Web/Forensix.db\")\n",
    "cur = sqlite.cursor()\n",
    "cur.execute(\"DELETE FROM EVIDENCES\")\n",
    "cur.close()\n",
    "sqlite.commit()\n",
    "sqlite.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996db625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
