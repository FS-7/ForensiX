{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03933ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch \n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float32 if torch.cuda.is_available() else torch.float16\n",
    "gemma = \"google/gemma-2-2b-it\"\n",
    "nlp_model = pipeline(\"text-generation\", model=gemma, model_kwargs={\"torch_dtype\": torch_dtype}, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e22956",
   "metadata": {},
   "source": [
    "NATURAL LANGUAGE QUERYING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"display contact with foreign prefix numbers\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \n",
    "        f\"\"\"\n",
    "        Context: You are a SQL generator. \n",
    "        Given the following database schema:\n",
    "            Table: Messages\n",
    "            Columns:\n",
    "            - id (integer)\n",
    "            - Address (text)\n",
    "            - Date Sent (date)\n",
    "            - Date Received (date)\n",
    "            - Type (text)\n",
    "            - Body (text)\n",
    "            - Seen (boolean)\n",
    "            \n",
    "            Table: Contacts\n",
    "            Columns:\n",
    "            - id (integer)\n",
    "            - name (text)\n",
    "            - number (number)\n",
    "            - email (text)\n",
    "            \n",
    "            Table: Call Logs\n",
    "            Columns:\n",
    "            - id (integer)\n",
    "            - Owner (text)\n",
    "            - Date Time (number)\n",
    "            - Duration (number)\n",
    "            - Type (text)\n",
    "            \n",
    "            Table: Files\n",
    "            Columns:\n",
    "            - path (text)\n",
    "            - name (text)\n",
    "            - parent (text)\n",
    "            - size (number)\n",
    "            - datetime (datetime)\n",
    "            - ext (text) alias type\n",
    "            \n",
    "        Convert the following user question into a correct, safe SQL query. \n",
    "        Return only SQL, no explanations.\n",
    "        Query: create a query to {query}\n",
    "        \"\"\"}\n",
    "]\n",
    "\n",
    "outputs = nlp_model(messages, max_new_tokens=128)\n",
    "\n",
    "assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "print(assistant_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a69184",
   "metadata": {},
   "source": [
    "TEXT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \n",
    "        f\"\"\"\n",
    "        {text}\n",
    "        Query: classify the text into one of the following categories: Normal, Threat, identity_attack, sexual_explicit, toxicity, extremism\n",
    "        \"\"\"}\n",
    "]\n",
    "\n",
    "outputs = nlp_model(messages, max_new_tokens=128)\n",
    "assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d0a8bf",
   "metadata": {},
   "source": [
    "SUMMARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Your so-called Dawn Legion is a stain on this realm. Our Order will reshape the world in shadow  whether your light survives or not. Your shadows are nothing but fear masquerading as strength. The Legion will burn away every twisted doctrine your Order spreads. You cling to that naive radiance like it protects you. The Obsidian Order’s rise is inevitable. Oppose us  and you’ll be swept aside with the rest of the deluded. We don’t bow to tyrants hiding behind darkness. If it’s a clash of convictions you want the Legion stands ready. We won’t let your corruption swallow the realm. \"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \n",
    "        f\"\"\"\n",
    "        {text}\n",
    "        Query: Summarize this\n",
    "        \"\"\"}\n",
    "]\n",
    "\n",
    "outputs = nlp_model(messages, max_new_tokens=128)\n",
    "print(outputs)\n",
    "assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "print(assistant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6248e0",
   "metadata": {},
   "source": [
    "CONVERT TO NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "DB_LOCATION = \"./data/\"\n",
    "id = \"sms.db\"\n",
    "\n",
    "def run_query(query):\n",
    "    if str(query).lower().startswith(\"select\"):\n",
    "        return\n",
    "    conn = sqlite3.connect(\"./data/sms.db\")\n",
    "    cur = conn.cursor()\n",
    "    output = cur.execute(\n",
    "        query,\n",
    "        []\n",
    "    ).fetchall()\n",
    "    return output\n",
    "\n",
    "results = run_query(query)\n",
    "print(results)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": \n",
    "        f\"\"\"\n",
    "        Data: {results}\n",
    "        Convert the following data in human readable format\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "try:\n",
    "    outputs = nlp_model(messages, max_new_tokens=256)\n",
    "    assistant_response = outputs[0][\"generated_text\"][-1][\"content\"].strip()\n",
    "    print(assistant_response)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
